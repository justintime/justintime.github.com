
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>SysAdmin's Journey</title>
  <meta name="author" content="Justin Ellison">

  
  <meta name="description" content="Took a fair amount of googling around to find the solution to this one. With
the Node Gallery 3.x branch, we
needed a way to quickly add an image to &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://justintime.github.com/blog/page/3/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="SysAdmin's Journey" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-5430710-2']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">SysAdmin's Journey</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:justintime.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/contact">Contact</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/content/2010/01/26/display-cck-filefield-or-imagefield-upload-widget-your-own-custom-form">Display a CCK Filefield or Imagefield Upload Widget on Your Own Custom Form</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-01-26T00:00:00-06:00" pubdate data-updated="true">Jan 26<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Took a fair amount of googling around to find the solution to this one. With
the <a href="http://drupal.org/project/node_gallery">Node Gallery</a> 3.x branch, we
needed a way to quickly add an image to an existing gallery. We could have
displayed the whole node form, but there&#8217;s a lot of things on that form that
we can just use the defaults for 99% of the time. We need just three fields
filled in: Title, Caption, and the imagefield itself.  To use the same
imagefield widget that handles all the hard work for you on the node add field
on your own field, first create a handler in hook_menu such as this:</p>

<div>
  <pre><code class='php'>$items['node/%node_gallery_gallery/upload'] = array(
    'title' =&gt; 'Upload New Image',
    'page callback' =&gt; 'drupal_get_form',
    'page arguments' =&gt; array('node_gallery_upload_image_form', 1),
    'access callback' =&gt; 'node_gallery_user_access',
    'access arguments' =&gt; array('upload', 1),
    'file' =&gt; 'node_gallery.pages.inc',
    'type' =&gt; MENU_LOCAL_TASK,
  );</code></pre>
</div>


<p>Then, in node_gallery.pages.inc, you create the form function
that does the work:</p>

<div>
  <pre><code class='php'>function node_gallery_upload_image_form($form_state, $gallery) {
  $imagetype = 'node_gallery_image';
  $form_id = $imagetype . '_node_form';
  
  module_load_include('inc', 'content', 'includes/content.node_form');
  $field = content_fields('field_node_gallery_image',$imagetype);
  
  $form['title'] = array(
    '#title' =&gt; t('Title'),
    '#type' =&gt; 'textfield',
    '#required' =&gt; TRUE,
    '#weight' =&gt; -10,
  );
  $form['body'] = array(
    '#title' =&gt; t('Caption'),
    '#type' =&gt; 'textarea',
    '#weight' =&gt; -9,
  );
  $form['type'] = array(
    '#type' =&gt; 'value',
    '#value' =&gt; $imagetype,
  );
  $form['gid'] = array(
    '#type' =&gt; 'value',
    '#value' =&gt; $gallery-&gt;nid,
  );
  $form['#field_info']['field_node_gallery_image'] = $field;
  $form['#field_info']['field_node_gallery_image']['#required'] = TRUE;
  $form += (array) content_field_form($form, $form_state, $field);
  
  $form['submit'] = array('#type' =&gt; 'submit', '#weight' =&gt; 10, '#value' =&gt; 'Save');
  
  return $form;
}</code></pre>
</div>


<p>This is pretty straightforward, up
until lines 28 - 30. Those three lines setup the form array and then append
the results from content_field_form() to our existing form. Still, very easy,
but I wasn&#8217;t able to find any documentation on how to do this. Just in case
you&#8217;re curious, here&#8217;s the submit handler for that form.</p>

<div>
  <pre><code class='php'>function node_gallery_upload_image_form_submit($form, &amp;$form_state) {
  global $user;
  $image = new stdClass;
  $image-&gt;uid = $user-&gt;uid;
  $image-&gt;name = (isset($user-&gt;name) ? $user-&gt;name : '');
  $values = $form_state['values'];
  foreach ($values as $key =&gt; $value) {
    $image-&gt;$key = $value;
  }
  node_gallery_image_save($image);
}</code></pre>
</div>


<p>Nothing new
there. The end result is a nice looking, concise form that allows you to
quickly upload an image to a gallery. Sweet!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/content/2010/01/20/drupal-meet-hudson-hudson-drupal">Drupal, Meet Hudson; Hudson, Drupal&#8230;</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-01-20T00:00:00-06:00" pubdate data-updated="true">Jan 20<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>At $work, we use <a href="https://hudson.dev.java.net/">Hudson</a> extensively, and it
rocks. For those who don&#8217;t know already, Hudson is an implementation of
<a href="http://en.wikipedia.org/wiki/Continuous_integration">Continuous Integration</a>
that is remarkably easy to use. I wrote about my <a href="http://sysadminsjourney.com/content/2009/08/13/hudson-cruisecontrol-2">first impressions of Hudson</a>
previously. Hudson&#8217;s original audience was Java developers using Ant or Maven,
but with plugins and some hacking, we can make it do some things for us as
module contributors to Drupal.  I&#8217;ve been cutting my Drupal developer teeth by
working pretty intensively on a few modules for Drupal - <a href="http://drupal.org/project/node_gallery">Node Gallery</a> and it&#8217;s derivatives. We are
hitting a crucial point in development where we are switching from the old way
of defining fields on a node to using CCK. While the module is still in alpha,
it&#8217;s still in use by quite a few sites - as of this writing it&#8217;s number 465 on
the list of Drupal modules. Not exactly the spotlight, but we can&#8217;t go
breaking things without making people angry either. I figured this would be
the perfect place for Hudson - it will let you know when you break something.</p>

<h3>Pieces of the Puzzle</h3>

<p>Here&#8217;s the pieces you&#8217;ll need:</p>

<ul>
<li>A linux server with Java, a working Drupal install (that may get broken at times) and the cvs command-line utility.</li>
<li>These Drupal modules installed and enabled: <a href="http://drupal.org/project/drush">drush</a>, <a href="http://drupal.org/project/coder">coder</a>, and optionally <a href="http://drupal.org/project/simpletest">simpletest</a>.</li>
<li>Some time on your hands</li>
</ul>


<h3>The shell script</h3>

<p>This is the most important piece of the setup. By utilizing Hudson&#8217;s
environment variables, we can make this as portable as possible. By using the
same script for all Hudson jobs, changing the script automatically changes all
of our jobs at once. Let&#8217;s dive right in:</p>

<div>
  <pre><code class='bash'>#!/bin/bash
#set -x

PHP=/usr/bin/php
DRUSH_PATH=/apps/drupal/drush
DRUPAL_PATH=/apps/drupal/drupal_core
MODULES_DIR=$DRUPAL_PATH/sites/ngdemo.sysadminsjourney.com/modules
SITE=&quot;http://ngdemo.sysadminsjourney.com/&quot;

DRUSH=&quot;$PHP $DRUSH_PATH/drush.php -n -r $DRUPAL_PATH -i $DRUPAL_PATH -l $SITE&quot;
EXITVAL=0

# Check our syntax
PHP_FILES=`/usr/bin/find $WORKSPACE -type f -exec grep -q '&lt;?php' {} \; -print`
for f in $PHP_FILES; do
  $PHP -l $f
  if [ $? != 0 ]; then
    let &quot;EXITVAL += 1&quot;
    echo &quot;$f failed PHP lint test, not syncing to ngdemo website.&quot;
    exit $EXITVAL
  fi
done

#Install the files
/usr/bin/rsync -a --delete $WORKSPACE/* $MODULES_DIR/$JOB_NAME

#Run update.php
$DRUSH updatedb -q --yes

#Run coder
CODER_OUTPUT=`$DRUSH coder no-empty`
if [ -n &quot;`echo $CODER_OUTPUT | grep $JOB_NAME`&quot; ]; then
  $DRUSH coder no-empty
  echo &quot;Coder module reported errors.&quot;
  let &quot;EXITVAL += 1&quot;
fi

#Run potx
cd $MODULES_DIR/$JOB_NAME
../potx/potx-cli.php
if [ $? != 0 ]; then
  let &quot;EXITVAL += 1&quot;
  echo &quot;POTX failed.&quot;
fi
if [ -e $MODULES_DIR/$JOB_NAME/general.pot ]; then
  cp $MODULES_DIR/$JOB_NAME/general.pot $MODULES_DIR/../files/$JOB_NAME.pot
fi

exit $EXITVAL</code></pre>
</div>


<p>Lines 14 through 23 find all files in $WORKSPACE (which is
set by Hudson) that have the &#8216;must** name your Hudson project the same as the
module name. Also note that your Hudson user needs to have write access to the
specific module directory that it&#8217;s installing. Line 29 runs drush so that it
invokes update.php, and answers yes to all questions. Lines 32 through 37 runs
the default code review from the coder module. You will have had to set this
up initially via the web interface. It then scans through that output looking
for any complaints about our $JOB_NAME, and if found, prints it to stdout and
increments our exit value by 1. Note we don&#8217;t exit here, as it&#8217;s a non-fatal
error. However, Hudson will treat it as a failed build and email everyone
about it. Lines 40 through 48 runs the Translation Template Extractor command
line utility against our module. It then copies the general.pot to the files
directory. Again, the user running Hudson will need write access for this to
work properly. If the potx-cli.php script should exit uncleanly, we increment
our exit value by one. Last in my script, we simply exit with whatever value
we have ended up with at this point. Again, if Hudson sees anything other than
a zero, it will email everyone about it. Since the modules I&#8217;m working on
don&#8217;t have Simpletest tests ready yet, I don&#8217;t run them in this script.
However, it&#8217;s on the horizon, and can be ran easily using run-tests.sh. Note
that there is <a href="http://drupal.org/node/602332">a patch</a> that will cause run-
tests.sh to output it&#8217;s results in a JUnit style output, which Hudson
understands fully. If you implement this, I strongly recommend applying that
patch.</p>

<h3>Hudson Setup</h3>

<p>Now that we have our script ready, we need to setup our Hudson job. Note that
installing Hudson itself is outside the scope of this article - it&#8217;s
refreshingly easy and doesn&#8217;t need repeating here. There are two things you
must do before creating the build task. First, setup your &#8220;E-mail
Notification&#8221; section according to your mail server at
http://myhudsonserver:8080/configure. Also, you will need to install the &#8220;URL
Change Trigger&#8221; plugin by navigating to
http://myhudsonserver:8080/pluginManager/available. Once you install that
plugin, create a new job. In my case, the job was named &#8216;node_gallery&#8217;, since
that&#8217;s the name of the Drupal module I was working with. Select &#8216;Build a free-
style software project&#8217; when asked. Under the &#8220;Source Code Management&#8221;
section, select &#8220;CVS&#8221;, and then fill in the CVSROOT of the project you&#8217;re
working with. In my case, it was
&#8216;:pserver:anonymous:anonymous@cvs.drupal.org:/cvs/drupal-contrib&#8217;. Next, fill
in the path to the module in the &#8220;Module(s)&#8221; form - for me it&#8217;s
&#8216;contributions/modules/node_gallery/&#8217;. If you&#8217;re working with CVS HEAD, leave
the Branch field empty, otherwise type in the branch name there.
<strong>IMPORTANT:</strong> to avoid abusing Drupal.org&#8217;s already overloaded CVS server
with cvs logins once every 5 minutes, we will point Hudson instead to the RSS
feed for the CVS log messages. Make sure &#8220;Poll SCM&#8221; is unchecked, and check
&#8220;Build when a URL&#8217;s content changes&#8221;. To obtain the URL, you need the node id
of your project. There&#8217;s many ways to do this, but you can find it by going to
the project&#8217;s Drupal.org page and click on &#8220;View CVS Messages&#8221;. From that
page, click the orange RSS icon at the bottom left of that page. Copy and
paste that URL into the URL field in Hudson. Under the Build section, click
&#8220;Add build step&#8221;, and select &#8220;Execute Shell&#8221;. In the resulting &#8220;Command&#8221;
textarea, type the full path to the shell script we setup above. The final
section, &#8220;Post-build actions&#8221; is up to you, but you&#8217;ll likely want to enable
email notifications. Place a checkmark in the &#8220;Email Notification&#8221; box, and
type in the email addresses of the desired recipients. Click Save, and you&#8217;re
done! Hudson will start doing a CVS checkout of your project, and will start
running tests on it. It will email you once anything goes wrong, and will
notify you again when the problem is resolved. It will only run these tests
after someone commits code to CVS, so you will likely need to hit the &#8220;Build
Now&#8221; link in the left nav a few times. We&#8217;ve really only scratched the surface
of what Hudson can do. You can track performance using JMeter, add all kinds
of crazy plugins, require logins, the list goes on and on. While this helps,
it&#8217;s still nowhere as helpful as a Ant/Maven job can be. Hopefully this
article is enough to spark some interest from the Drupal community so that we
can write some better continuous integration code in the future. Also, I&#8217;m far
from being an expert on either Drupal or Hudson. I wrote my first code for
Drupal in November of 2009, and I only tinker with Hudson on occasion at work.
Hudson works so well, it&#8217;s one of those &#8220;set it and forget it&#8221; apps. I would
love for readers to leave comments on any mistakes I might have made, or
possible improvements I may have missed!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/content/2009/12/29/zfs-trenches-presentation-lisa-09">ZFS in the Trenches Presentation at LISA 09</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2009-12-29T00:00:00-06:00" pubdate data-updated="true">Dec 29<span>th</span>, 2009</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Just got the chance to finally sit down and watch <a href="http://www.cuddletech.com">Ben
Rockwood&#8217;s</a> presentation at LISA 09: <a href="http://slx.sun.com/1179275886">ZFS in the
Trenches</a>. If you are even thinking about ZFS
and how it works, it&#8217;s a very informative presentation. There is very little
marketing-speak, and he very specifically targets sysadmins as his audience.
Great stuff! Of interesting note about his comparison of fsstat vs iostat, our
Apache webservers routinely see about 5MB/sec reads being asked of ZFS, but
the actual iostat on the disk shows that almost all of that traffic is being
served up from ARC.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/content/2009/12/21/quicktip-fix-eclipse-galileo-buttons-ubuntu-910">QuickTip: Fix Eclipse Galileo Buttons on Ubuntu 9.10</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2009-12-21T00:00:00-06:00" pubdate data-updated="true">Dec 21<span>st</span>, 2009</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>There&#8217;s a nasty upstream bug in GTK present in Ubuntu 9.10 that makes Eclipse
Galileo all but unusable &#8211; specifically it makes clicking many buttons with
the mouse just stop working. You can use tab and spacebar to make it work, but
that&#8217;s not much of a workaround. All you need to do is set an environment
variable before starting Eclipse:</p>

<pre><code>export GDK_NATIVE_WINDOWS=true
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/content/2009/12/18/share-your-eclipse-plugins-and-configurations-across-platforms">Share Your Eclipse Plugins and Configurations Across Platforms</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2009-12-18T00:00:00-06:00" pubdate data-updated="true">Dec 18<span>th</span>, 2009</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><img src="/assets/images/eclipse-logo-white.jpg" alt="" />Over the years, I&#8217;ve come to know
and love <a href="http://eclipse.org">Eclipse</a>. Though it has roots in Java,
ironically, I use Eclipse for just about everything except for coding Java (if
I wrote Java code, I&#8217;m sure I&#8217;d use Eclipse). Eclipse is great for <a href="http://subclipse.tigris.org">browsing
Subversion</a>, <a href="http://www.eclipse.org/pdt">coding
PHP</a>, <a href="http://e-p-i-c.sourceforge.net">coding
Perl</a>, and even <a href="http://sourceforge.net/project/shelled">coding shell
scripts</a>. For die hards like me,
there&#8217;s the <a href="http://viplugin.com">viPlugin</a> that allows you to use all the vi
commands you know and love within Eclipse. About the time you get your perfect
Eclipse setup established, you buy a new laptop on a new platform. Or, in my
case, I have three &#8220;primary&#8221; development workstations, each on a different OS.
The rest of this article will show you how to hook
<a href="http://dropbox.com">Dropbox</a> into your Eclipse installation, allowing you to
share your plugins and configurations across different versions of Eclipse, on
different machines, and even on different platforms.</p>

<p>Truth be told, doing this type of setup with Eclipse was actually easier to do
with older versions of Eclipse. Since they&#8217;ve moved to the p2 provisioning
system, it became a little harder to do, but still very possible. After much
googling, I finally came across <a href="http://stackoverflow.com/questions/582391/installing-eclipse-3-4%0A-plugins-in-a-directory-other-than-eclipsehome-plugins">this StackOverflow
question</a> that gave me the
pieces I needed to set this all up.</p>

<p>A little prep work on the frontend will save us a huge amount of time in
maintenance. Note that I use Dropbox in this article, but any similar service
should do. We&#8217;ll setup our Linux install first, since we can script things a
little easier there. Go ahead and install Dropbox and Eclipse - they&#8217;re both
very straightforward installations.</p>

<p>Let&#8217;s assume that our Dropbox directory is directly under our home directory,
and our eclipse installation is in ~/eclipse.  Let&#8217;s setup some environment
variables and create our directory structure:</p>

<pre><code>export DROPDIR=~/Dropbox
export ECLIPSEDIR=~/eclipse
cd $DROPDIR
mkdir eclipse-custom
cd eclipse-custom
# Create our shared extension dir
mkdir extensions
# Create our workspace dir
mkdir shared-workspace
</code></pre>

<p>With our directory structure setup, it&#8217;s time to pick a plugin to install.
Let&#8217;s do <a href="http://www.eclipse.org/pdt">PDT</a>. The key here is that we start
Eclipse by pointing it to a new configuration directory which lives on our
Dropbox account, and install the new extension. This will force Eclipse to
install the plugin to the Dropbox directory, instead of the local directory.
Start Eclipse like so:</p>

<pre><code>eclipse -configuration $DROPDIR/eclipse-custom/extensions/pdt/eclipse/configuration
</code></pre>

<p>Note that you can change the &#8216;pdt&#8217; portion of that path to whatever you
choose, but you must include the trailing eclipse/configuration portion. Once
in Eclipse, go ahead and install PDT just as you normally would, then exit
Eclipse.</p>

<p>Now that we&#8217;ve installed the PDT extension to a shared location, it&#8217;s time to
point our local Eclipse installation to it. I wrote a quick script to do just
that:</p>

<pre><code>mkdir $ECLIPSEDIR/links
cd $DROPDIR/eclipse-custom/extensions
for d in `ls`; do
  echo "path=`pwd`/$d" &gt; $ECLIPSEDIR/links/$d.link
done
</code></pre>

<p>This script creates a directory named &#8216;links&#8217; in your Eclipse local
installation, and creates a file for every extension that contains one line
containing the path to the target extension. Now, start Eclipse. For some odd
reason, the extensions wouldn&#8217;t actually install until after I restarted
Eclipse a second time, so you may need to do the same. You should now see your
plugin in Eclipse.</p>

<p>Please note that if you&#8217;re doing cross-platform development, you&#8217;ll save
yourself some headache by <strong>not</strong> sharing the subclipse plugin. There&#8217;s too
much of that plugin that depends on the underlying OS to share effectively.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/content/2009/12/15/nginx-performs-well-solaris-10-x86">NGINX Performs Well on Solaris 10 X86</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2009-12-15T00:00:00-06:00" pubdate data-updated="true">Dec 15<span>th</span>, 2009</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><img src="/assets/images/nginx.gif" alt="" />Just a quick posting of some simple benchmarks
today. Please note, these are not the be all, end all performance results that
allow everyone to scream from atop yonder hill that Solaris performs better
than Linux! This was just me doing a little due dilligence. I like Solaris 10,
and wanted to run it on our webservers. We&#8217;re looking at using NGINX to serve
up some static files, and I wanted to make sure it performed like it should on
Solaris 10 before deploying it - you know, right tool for the job and all. So,
disclaimers aside, here&#8217;s what I found.</p>

<h2>The Hardware</h2>

<p>The hardware I tested was a Dell PowerEdge R610, with 12GB RAM, and 2x4 Core
Nehalem CPU&#8217;s. SATA disks were used with the internal RAID controller, but no
RAID was configured.</p>

<h2>The Benchmarks</h2>

<p>I used ApacheBench, as shipped with Glassfish Webstack 1.5. Yes, I know,
there&#8217;s all kinds of flaws with ApacheBench, but the key here isn&#8217;t the
benchmarking tool, it&#8217;s that the tool and it&#8217;s configuration remain the same.
Here&#8217;s the command line I used:</p>

<p><code>/opt/sun/webstack/apache2/2.2/bin/ab -n1000000 -k -c 2000
http://localhost/static/images/logo.jpg</code></p>

<h2>CentOS 5.4</h2>

<p>I installed CentOS 5.4, ran yum to get all the updates possible. I then
installed NGINX 0.7.64 from source, and simply copied one image file into the
document root. I did a few sysctl tweaks for buffers and whatnot, but found
later that they didn&#8217;t impact the benchmark. Here&#8217;s what ApacheBench running
on the local host had to say:</p>

<pre><code>This is ApacheBench, Version 2.3 &lt;$Revision: 655654 $&gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking localhost (be patient)
Completed 100000 requests
Completed 200000 requests
Completed 300000 requests
Completed 400000 requests
Completed 500000 requests
Completed 600000 requests
Completed 700000 requests
Completed 800000 requests
Completed 900000 requests
Completed 1000000 requests
Finished 1000000 requests


Server Software:        nginx/0.7.64
Server Hostname:        localhost
Server Port:            80

Document Path:          /static/images/logo.jpg
Document Length:        4404 bytes

Concurrency Level:      2000
Time taken for tests:   21.916 seconds
Complete requests:      1000000
Failed requests:        0
Write errors:           0
Keep-Alive requests:    990554
Total transferred:      4625275893 bytes
HTML transferred:       4407166476 bytes
Requests per second:    45629.29 [#/sec] (mean)
Time per request:       43.831 [ms] (mean)
Time per request:       0.022 [ms] (mean, across all concurrent requests)
Transfer rate:          206101.61 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   3.9      0     135
Processing:     0   43  67.8     27     676
Waiting:        0   43  67.7     27     676
Total:          0   44  68.1     27     676

Percentage of the requests served within a certain time (ms)
  50%     27
  66%     41
  75%     49
  80%     53
  90%     72
  95%    202
  98%    245
  99%    342
 100%    676 (longest request)
</code></pre>

<p>No matter how you slice it, that&#8217;s pretty darn fast. I knew that Solaris 10
had a completely rewritten TCP/IP stack optimized for multithreading, and that
it should keep right up with Linux. However, NGINX uses different event models
for Linux and Solaris 10 (epoll vs eventport), so I wanted to make sure there
weren&#8217;t any major differences in performance.</p>

<h2>Solaris 10</h2>

<p>I installed Solaris 10 x86, ran pca to get all the updates possible. I then
installed NGINX 0.7.64 from source, and simply copied one image file into the
document root. Here&#8217;s what ApacheBench running on the local host had to say:</p>

<pre><code>Server Software:        nginx/0.7.64
Server Hostname:        localhost
Server Port:            80

Document Path:          /static/images/logo.jpg
Document Length:        4404 bytes

Concurrency Level:      2000
Time taken for tests:   21.728 seconds
Complete requests:      1000000
Failed requests:        0
Write errors:           0
Keep-Alive requests:    991224
Total transferred:      4623536714 bytes
HTML transferred:       4405506168 bytes
Requests per second:    46023.73 [#/sec] (mean)
Time per request:       43.456 [ms] (mean)
Time per request:       0.022 [ms] (mean, across all concurrent requests)
Transfer rate:          207805.08 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    1  71.9      0    4434
Processing:     0   42  57.2     29    1128
Waiting:        0   41  56.0     29    1128
Total:          0   43  98.6     29    4473

Percentage of the requests served within a certain time (ms)
  50%     29
  66%     35
  75%     42
  80%     50 
  90%     74
  95%    108
  98%    176
  99%    256
 100%   4473 (longest request)
</code></pre>

<p>Again, very impressive results. Overall, it appeared as though Solaris+NGINX
was just a few millis faster than CentOS+NGINX in most cases, but certainly
not enough to change your mind of what platform to use. If you notice the 4.5
second request on the Solaris box, I&#8217;m pretty sure that&#8217;s a TCP retransmit
that I can work out with ndd tuning.</p>

<h2>The Verdict</h2>

<p>NGINX is freaking fast. My hunch is that it&#8217;s so fast, that I&#8217;m actually
running up against the limits of ApacheBench, not NGINX &#8211; but that&#8217;s just a
gut feeling. The verdict is that you won&#8217;t be making a mistake going with
either Linux or Solaris when setting up your NGINX server.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/content/2009/11/30/ask-saj-what-do-apache-logs-50gb">Ask SAJ: What to Do With Apache Logs > 50GB?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2009-11-30T00:00:00-06:00" pubdate data-updated="true">Nov 30<span>th</span>, 2009</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Our site at $work is generating Apache logs that, when combined sequentially
into one file, are larger than 50GB in size for one day&#8217;s worth of traffic.
AWStats&#8217; perl script pretty much chokes when working on this much data. Last I
checked, Webalizer wasn&#8217;t much different, and probably wouldn&#8217;t scale up to
that amount of data either. Does anyone out there have any advice on a
commercial solution for Apache log analysis that can scale up like that?</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/content/2009/11/16/tip-split-components-across-domains-performance-goal-yahoo">Tip for &#8220;Split Components Across Domains&#8221; Performance Goal From Yahoo!</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2009-11-16T00:00:00-06:00" pubdate data-updated="true">Nov 16<span>th</span>, 2009</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Just thought I&#8217;d pass this little tidbit out there - we fixed it by pure luck
on the first try. Yahoo unselfishly provides a document titled <a href="http://developer.yahoo.com/performance/rules.html">Best Practices
for Speeding Up Your
Website</a>. While some of the
rules offered there aren&#8217;t applicable for all sites, it&#8217;s a great document and
if you run a website, you should read it. At $work, part of our last code drop
was to push out a feature that enabled &#8220;Split Components Across Domains&#8221;. From
the article <a href="http://yuiblog.com/blog/2007/04/11/performance-research-%0Apart-4/">Performance Research, Part 4: Maximizing Parallel Downloads in
the Carpool Lane</a>:</p>

<blockquote><p>Our rule of thumb is to increase the number of parallel downloads by using
at least two, but no more than four hostnames. Once again, this underscores
the number one rule for improving response times: reduce the number of
components in the page.</p></blockquote>

<p>I&#8217;m here to tell you, if you have AOL users surfing your site, <strong>do not use
four hostnames</strong>.  When we pushed this feature up to production, we had one
hostname that served up the HTML, and we had four hostnames that served up
imagery (all these hostnames pointed back to the same IP, but doing this
allows a performance boost in the browser). For this example, let&#8217;s say that
www.mydomain.com is the HTML hostname; img0.mycontent.com, img1.mycontent.com,
img2.mycontent.com, and img3.mycontent.com were the imagery servers. This most
certainly improved performance on the client side, but we started receiving
some reports from a few users that they were no longer able to see <strong>any</strong>
imagery on the site since we dropped the new code. We immediately knew what
was causing the issue, but had no idea why, or how far spread out it was.
Well, after poking around some of the &#8220;big boys&#8221; websites such as Amazon, we
noticed that while all of them separated their components as suggested by
Yahoo!, all of them used only one hostname for the imagery. We quickly
configured our webapp to only use www.mydomain.com for the HTML, and
img0.mycontent.com for the imagery. Once we did that, our AOL users were again
able to see imagery. Now, I have no idea how widespread the issue was. I know
it was limited to users of the AOL browser, and I suspect it&#8217;s probably a bug
in a specific version of their browser. However, if your site needs to provide
compatibility to the most users possible, you may want to use just one
separate hostname for splitting components. I hope this helps someone else!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/content/2009/11/13/which-directory-server-and-why">Which Directory Server and Why?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2009-11-13T00:00:00-06:00" pubdate data-updated="true">Nov 13<span>th</span>, 2009</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>One of my projects for 2010 is to get a reliable directory server in place. I
was going to post a poll to my readers asking what they felt was the best DS,
but <a href="http://www.cuddletech.com/blog/index.php">Ben Rockrood</a> beat me to it
with his article <a href="http://www.cuddletech.com/blog/pivot/entry.php?id=1094">Community Poll: Whats your favorite Directory
Server?</a>. It&#8217;s likely
that most of the readers of this blog already read Ben&#8217;s too, but if you don&#8217;t
it&#8217;s a great blog to subscribe to. If you have any input into the debate on
what DS is the best, <a href="http://www.cuddletech.com/blog/pivot/entry.php?id=1094">head on over and leave a
comment</a>!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/content/2009/11/12/quicktip-make-life-easier-ssh-copy-id">QuickTip: Make Life Easier With Ssh-copy-id</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2009-11-12T00:00:00-06:00" pubdate data-updated="true">Nov 12<span>th</span>, 2009</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>How many times have you ran through this series of events?</p>

<div>
  <pre><code class='console'>$ cat ~/.ssh/id_dsa.pub
...copy output to clipboard...
$ ssh myhost
...enter password...
myhost$ vi ~./ssh/authorized_keys
...paste public key and save...
myhost$ exit</code></pre>
</div>


<p>Thanks to bash&#8217;s tab completion, I
happened upon <strong>ssh-copy-id</strong>. Instead of all that above, just do this:</p>

<div>
  <pre><code class='console'>$ ssh-copy-id myhost
...enter password...</code></pre>
</div>


<p>You&#8217;re done!</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/4/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/2/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/content/using-git-submodules-dynamic-puppet-environments">Using Git Submodules with Dynamic Puppet Environments</a>
      </li>
    
      <li class="post">
        <a href="/content/2011/11/14/vpsnet-review">VPS.net review</a>
      </li>
    
      <li class="post">
        <a href="/content/2011/10/19/its-not-you-its-me-call-node-gallery-co-maintainers">It&#8217;s not you, it&#8217;s me: Call for Node Gallery co-maintainers</a>
      </li>
    
      <li class="post">
        <a href="/content/2011/09/20/drupal-heroku">Drupal on Heroku</a>
      </li>
    
      <li class="post">
        <a href="/content/2011/04/19/selecting-right-cdn-your-website">Selecting the right CDN for YOUR website</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/justintime">@justintime</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'justintime',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("justinellison", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/justinellison" class="twitter-follow-button" data-show-count="false">Follow @justinellison</a>
  
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - Justin Ellison -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'sysadminsjourney';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
